{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cWejUm1n_ee"
      },
      "source": [
        "## Exploring the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLQjOsXAoQC9"
      },
      "source": [
        "### Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJ8RLsXMoVdA"
      },
      "outputs": [],
      "source": [
        "# Upload kaggle config file\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWLBO2HJocvE"
      },
      "outputs": [],
      "source": [
        "# Make a directory named kaggle and copy the kaggle.json file there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "# Change the permission of the file\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRBYSJ9LofHP"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "!kaggle datasets download -d xhlulu/recursion-cellular-image-classification-224-jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzNkfEmwowwX"
      },
      "outputs": [],
      "source": [
        "# Extract the data\n",
        "!mkdir /content/recursion-cellular-image-classification\n",
        "!unzip /content/recursion-cellular-image-classification-224-jpg.zip -d /content/recursion-cellular-image-classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blZPTURHo0vo"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwnX56ch9FOr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqesJ9tLsfv1"
      },
      "outputs": [],
      "source": [
        "# Définir le chemin de dataset\n",
        "base_path = \"/content/recursion-cellular-image-classification/\"\n",
        "\n",
        "# Lire le ficher \"new_train.csv\"\n",
        "df = pd.read_csv(base_path + \"new_train.csv\")\n",
        "\n",
        "# Définir le nombre des classes\n",
        "num_classes = 100\n",
        "\n",
        "df = df[df.sirna < num_classes]\n",
        "\n",
        "# Preprocess les images\n",
        "def preprocess_images(df):\n",
        "    images = []\n",
        "    for i, row in df.iterrows():\n",
        "        path = base_path + \"train/train/\" + row['filename']\n",
        "        img = cv2.imread(path)\n",
        "        img = cv2.resize(img, (224, 224))        \n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "X = preprocess_images(df)\n",
        "y = to_categorical(df['sirna'], num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "    X,  # the data\n",
        "    y,  # the labels\n",
        "    test_size=0.2,  # the proportion of the data to use for testing\n",
        ")\n",
        "\n",
        "# Print the shape of the training and testing sets\n",
        "print('Training data shape:', train_data.shape)\n",
        "print('Training labels shape:', train_labels.shape)\n",
        "print('Testing data shape:', test_data.shape)\n",
        "print('Testing labels shape:', test_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rurd9dhY3iOq",
        "outputId": "e123b49f-bc52-4793-8507-6c8881a96d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (5273, 224, 224, 3)\n",
            "Training labels shape: (5273, 100)\n",
            "Testing data shape: (1319, 224, 224, 3)\n",
            "Testing labels shape: (1319, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9WxPFrZRWTO"
      },
      "source": [
        "### Simple model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBcNonHcRZal"
      },
      "outputs": [],
      "source": [
        "input_shape = (224, 224, 3)\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=input_shape, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Conv2D(64, (3,3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    Dropout(0.2),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ1hWRne1NJu"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH2YudLnUCQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815ec8f0-a76a-4faa-e16b-ef823913207c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "38/38 [==============================] - 448s 12s/step - loss: 57.1388 - accuracy: 0.0080 - val_loss: 5.4751 - val_accuracy: 0.0076\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 484s 13s/step - loss: 5.4630 - accuracy: 0.0124 - val_loss: 5.4472 - val_accuracy: 0.0038\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 479s 13s/step - loss: 5.4122 - accuracy: 0.0124 - val_loss: 5.4052 - val_accuracy: 0.0076\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 482s 13s/step - loss: 5.3511 - accuracy: 0.0126 - val_loss: 5.3627 - val_accuracy: 0.0095\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 480s 13s/step - loss: 5.3076 - accuracy: 0.0139 - val_loss: 5.3354 - val_accuracy: 0.0076\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "batch_size = 128\n",
        "\n",
        "history = model.fit(train_data, train_labels, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "318ZXaw71KDW"
      },
      "source": [
        "### with RestNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Imb98bc_1Fdk"
      },
      "outputs": [],
      "source": [
        "# Load the ResNet50 model\n",
        "resnet = ResNet50(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
        "\n",
        "# Add a few more layers for classification\n",
        "model = tf.keras.Sequential([\n",
        "    resnet,\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.layers[0].trainable = False\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "batch_size = 128\n",
        "\n",
        "history = model.fit(train_data, train_labels, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "metadata": {
        "id": "2JipV6mdw4gf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "c9WxPFrZRWTO",
        "VQ1hWRne1NJu"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}